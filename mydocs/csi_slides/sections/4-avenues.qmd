## Causal inference {.unnumbered .scrollable}

- **Goal**: Estimate the impact of losing one's *MÃ©decin Traitant* (Primary Care Provider, PCP), and looping back with Titouan's work

::: {.incremental}
- Up to a given time $t$, we have:

  - The covariate $X_{<t} \coloneqq (e_{<t}, t_{<t}, f_{<t})$, the medical history of the patient
  - $W_t$ is the (binary) treatment at time t, say: the patient has lost its PCP (death or retirement) before $t$
  - $Y_t (W_t)$, the binary outcome, indicating **whether death has occured within a given time window** $[t, t+ \delta_d]$

- We want to estimate the **Conditional Average Treatment Effect** (CATE):
$$ \tau(x, t) \coloneqq \mathbf{E}[Y_t(1) - Y_t(0) | X_{<t} = x]$$
:::

---

### Assumptions {.unnumbered .scrollable}

::: {.incremental}
- **SUTVA** : $$Y_t(w) = Y_t \quad \textit{ if } W_t = w$$

    - The others not having a PCP for a given amount of time does not influence my probability to die 
    - Only one version of treatment ?

- **Conditional ignorability - Unconfoundedness** $$ \forall w \in \{0,1\}, Y_t(w) \perp W_t \mid X_{<t}$$

- **Overlap** $$ 0 < \mathbb{P}(W_t = w | X_{<t} = x) < 1, \forall (w,x) \in ( \{0,1\}, \mathbb{R}^{d_{embed}})$$
:::

---

### Estimators of the CATE: S-learner{.unnumbered}

For a given time t, we define ${pos}_t$ as being the last position in the patient's pathway before $t$, and we define the embedding of the pathway:
$$ GPT^{\text{path}}(X_{<t}) \coloneqq GPT_{\theta^{*}}(X_{<t})_{{pos}_t} \in \mathbb{R}^{d_{embed}} $$

We train on the **calibration set** a head $g_{\phi}: \mathbb{R}^{d_{embed}} \times \mathbb{R}_{+}  \to [0,1]$, minimizing the BCE loss on death prediction - to obtain $\phi^{*}$.
$$ \hat{\tau}_{\text{SLearner}}(x) \coloneqq g_{\phi^{*}} (GPT^{\text{path}}(x), 1) - g_{\phi^{*}} (GPT^{\text{path}}(x), 0)$$

---

### Estimators of the CATE: R-learner{.unnumbered .scrollable}


::: {.incremental}
- Another approach consists in trying to model the *propensity score*, the probability of being treated given $X$.


- **A first head** $g_{\phi_{m}}: \mathbb{R}^{d_{embed}} \to [0,1]$ is trained on the **death prediction task**, so that for a given pathway $x$, $g_{\phi_{m}^{*}}(GPT^{\text{path}}(x))$ is *close* to the conditional mean outcome $m(x) = \mathbb{E}[Y_t | x]$.

- **Another head** $g_{\phi_{e}}: \mathbb{R}^{d_{embed}} \to  [0,1]$ is trained to **predict the treatment** $W_t$ of a given individual (minimizing a Mean Squared Error).

- Finally, we train the CATE estimator training a head $g_{\phi_{\tau}}: \mathbb{R}^{d_{embed}} \to [0,1]$ by minimizing the *R-loss*: \begin{align*}
\phi_{\tau}^{*} \in \arg\!\min_{\phi_{\tau}} \; & 
Y_t - g_{\phi_{m}^{*}}\left( GPT^{\text{path}}(X_{<t}) \right) \\
& - \left( W_t - g_{\phi_{e}^{*}}\left( GPT^{\text{path}}(X_{<t}) \right) 
\cdot g_{\phi_{\tau}}\left( GPT^{\text{path}}(X_{<t}) \right) \right)
\end{align*}
:::

---

### Estimators of the CATE: at the end of the day {.unnumbered .scrollable}

We have a lot of other meta-learners:

- T-learner
- X-learner
- DR-learner
- ...

![Target pipeline - from @abecassis:hal-04774700](images/ML-CI-pipe.png){fig-align="center" width="1000px"}

## Benchmarking {.unnumbered}

::: {.incremental}
- **How to compare embedding models ? What is a good embedding ?**
  1. Death or other outcome prediction
  2. R-loss (@doutreligneHowSelectPredictive2025)
  3. Visualization of the embedding space and _semantic understanding_ (metric t.b.d.)

- **Competitors:**
  - SVD-PPMI (static embeddings - SVD of a cooccurrence matrix with a given window size)
  - BERT (pure embeddings, no trajectories)
    - MLM pre-training task (@life2vec)
    - **Temporal window masking task**
  - GPT with next-token + time-to-event task (@Shmatko2025)
:::

## Improving pre-training task {.unnumbered}

- Exploring Posson loss - ground truth being **number of events** for each token, for each time window
- Exponential loss for time-to-event task (as in MOTOR (@steinberg2024motor))

We want ideally to have a generative model.

## Scaling {.unnumbered .scrollable}

- @chinchilla propose a **scaling law** for LLMs
  - Trade off between number of training tokens (train dataset size) and number of parameters in the model (model size)
  - Estimated optimal ratio: 
  $$\frac{\text{\# training tokens}}{\text{\# parameters}} = 20$$

    - is it the same for medical pathways ?

::: {.columns}
::: {.column width="50%"}
![From @Shmatko2025](images/delphi-graph.png){width=100%}
:::

::: {.column width="50%"}
![From @chinchilla](images/chinchilla.jpeg){width=100%}
:::
:::
