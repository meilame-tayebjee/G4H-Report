---
title: PhD Committee
subtitle: "**Embedding medical pathways for causal inference on healthcare supply shocks and patient outcomes**"
authors:
  - name: Meilame Tayebjee
    roles: writing
    corresponding: true
date: "2025-10-08"
date-format: "D MMMM YYYY"
lang: en-GB
bibliography: references.bib
slide-number: true
number-sections: true
format: 
  revealjs: 
    theme: serif
    toc: true
    toc-depth: 2   # show up to ## headings
    html-math-method: katex
    
css: custom.css
---


# Introduction

{{< include sections/intro.qmd >}}

# Related work

## Transformer-based models for medical pathway embedding {.unnumbered}


::: {#tbl-medpathway style="font-size: 0.5em;"}

| Model name | Model archi. | Pre-train. Task(s) | Fine-tun. task(s) | # Params | Training data size | Vocab size (type) |
|---|---|---|---|---|---|
| Delphi (@Shmatko2025) | NanoGPT | Next disease event + Time to event | None | 2M | 400k patients | 1,258 (ICD10)  |
| Life2Vec (@life2vec)| BERT | MLM + SOP | Mortality Prediction | 8M | 3M patients | ~700<br>(labour + ICD10) |
| TransformEHR (@yangTransformEHRTransformerbasedEncoderdecoder2023)| Encoder-Decoder | Visit masking: Given visits 1-3, predict all codes in visit 4 | Disease (pancreatic cancer) / Outcome (self harm) pred. | ? | 255M visits from 7M patients | ICD10 |

<!-- | BEHRT | BERT-style Transformer (EHR tokens + age/segment/position embeddings) | Multi-task disease onset prediction (301 cond.) | not reported (~6L, 12H, h=288) | ~1.6M pts |
| Med-BERT | BERT for structured diagnosis codes | Disease prediction (HF, pancreatic cancer) | ~17M | 28.5M pts |
| ClinicalBERT | BERT-base on clinical notes (MIMIC-III) | 30-day readmission + NLP tasks | ~110M (BERT-base) | 34,560 pts (downstream) |
| life2vec | BERT-like encoder (Performer hybrid) | Mortality + personality prediction | not reported | ~2.28M people |
| Hi-BEHRT | Hierarchical Transformer (local + global) | Risk prediction (HF, diabetes, CKD, stroke) | not reported | ~2.84M pts |
| CEHR-BERT | BERT w/ temporal & visit tokens | Hosp., death, HF diagnosis, readmission | not reported | ~2.4M pts |
| HEART | Relation-aware Transformer | 5 clinical tasks (2 datasets) | not reported | sizes vary |
| Transformer patient embedding (NPJ Dig Med 2025) | Transformer (codes→embedding) | Stratification, disease prediction | not reported | 1.05M pts (eMERGE) | -->

:::

## ML/DL for causal inference  {.unnumbered}

Several methodological papers:

- @abecassis:hal-04774700
- @

## Causal impact of PCP loss on health outcomes  {.unnumbered}

# Work done so far

## Data management {.unnumbered}

- Validation and EDA of the first delivered simplified tables: prestations and medications
- Jointure, cleaning and subsampling
  - So that any subsample can fit in vRAM
- Tokenization

IMAGE of data

## Notations {.unnumbered}
### Notations: dataset {.unnumbered}

**Dataset of medical pathways: ** For $i = 1, \dots, n$, $X_i \coloneqq (e_i, t_i, f_i)$, where:

::: {.incremental}
-  $e_i \in \mathbb{R}^{cs}$ are the tokenized events,  containing integers between $0$ and the vocabulary size $\lvert \mathcal{V} \rvert$
- $t_i \in \mathbb{R}^{cs}$ is the temporal vector, containing the dates
- $f_i \in \mathbb{R}^{2}$ corresponds to the patient general features, for now age and gender
:::

---

### Notations: model {.unnumbered}


- Embedding matrices of size $\mathbb{R}^{\lvert \mathcal{V} \rvert, d_{embed}}$ (vocab),  $\mathbb{R}^{2, d_{embed}}$ (gender) and $\mathbb{R}^{8, d_{embed}}$ (age class)
  - We use $t_i$ to have a _time-aware_ positional encoding using a sinusoidal encoding
  - A symbolic [START] token, composed of the summed embeddings of age and gender.

- **Causal** self-attention layers so that the Transformer-based model outputs ***causally contextualized embeddings***:
$$ GPT_{\theta}(X_i) \in \mathbb{R}^{cs, d_{embed}}$$

where $\theta$ parametrizes the neural network.

## Pre-training task {.unnumbered}

### Objectives {.unnumbered}


---

### Description {.unnumbered}

We predict for each token, if it will appear within the next $t$ days.

 We consider, simulatenously, several $t \in \mathcal{T}$, $\mathcal{T}$ being the sorted set of ***short term horizons***, typically 14, 30, 90, 180 days.


![](images/GPT-pretraining.png)

## First trained models {.unnumbered}


We trained a "large" model (40M params) and a "small" one (5M).

![ROC curve of the pre-training task for a given specialty on a test set of 10,000 patients.](../technical_report/images/GPT_results/roc_spe_3.png)

Still, the models converge quickly, and even small models achieve good convergence. This raises the (open) question of complexifying the task at some point.


# Avenues of work

## Causal inference {.unnumbered}

- **Goal**: Estimate the impact of losing one's *Médecin Traitant* (Primary Care Provider, PCP), and looping back with Titouan's work

::: {.incremental}
- Up to a given time $t$, we have:

  - The covariate $X_{<t} \coloneqq (e_{<t}, t_{<t}, f_{<t})$, the medical history of the patient
  - $W_t$ is the treatment at time t, say: **the proportion of days the patient has spent without a PCP during the period $[t- \delta_{PCP}, t]$, $\delta_{PCP}$** being a hyperparameter controlling the length of the window
  - $Y_t (W_t)$, the binary outcome, indicating **whether death has occured within a given time window** $[t, t+ \delta_d]$(which length $\delta_d$ is again chosen)
:::

---

### Assumptions {.unnumbered .scrollable}

::: {.incremental}
- **SUTVA** : $$Y_t(w) = Y_t \quad \textit{ if } W_t = w$$

    - The others not having a PCP for a given amount of time does not influence my probability to die 
    - Only one version of treatment ?

- **Conditional ignorability** $$ \forall w \in \mathbb{R}_{+}, Y_t(w) \perp W_t \mid X_{<t}$$

- **Overlap** $$ 0 < \mathbb{P}(W_t = w | X_{<t} = x) < 1, \forall (w,x) \in (\mathbb{R}_{+}, \mathbb{R}^{d_{embed}})$$
:::

---

### Estimators of the CATE: S-learner{.unnumbered}

For a given time t, we define ${pos}_t$ as being the last position in the patient's pathway before $t$, and we define the embedding of the pathway:

$$ GPT^{\text{path}}(X_{<t}) \coloneqq GPT_{\theta^{*}}(X_{<t})_{{pos}_t} \in \mathbb{R}^{d_{embed}} $$

$$ \hat{\tau}_{\text{SLearner}}(x, w) \coloneqq g_{\phi^{*}} (GPT^{\text{path}}(x), w) - g_{\phi^{*}} (GPT^{\text{path}}(x), 0)$$

where the baseline is "not having lost your PCP / having a PCP during all the period".

---

### Estimators of the CATE: R-learner{.unnumbered .scrollable}


::: {.incremental}
- Another approach consists in trying to model the *propensity score*, the probability of being treated given $X$.


- A first head $g_{\phi_{m}}: \mathbb{R}^{d_{embed}} \to [0,1]$ is trained on the death prediction task, so that for a given pathway $x$, $g_{\phi_{m}^{*}}(GPT^{\text{path}}(x))$ is *close* to the conditional mean outcome $m(x) = \mathbb{E}[Y_t | x]$.

- Another head $g_{\phi_{e}}: \mathbb{R}^{d_{embed}} \to \mathbb{R}_+$ is trained to predict the treatment $W_t$ of a given individual (minimizing a Mean Squared Error).

- Finally, we train the CATE estimator training a head $g_{\phi_{\tau}}: \mathbb{R}^{d_{embed}} \to [0,1]$ by minimizing the *R-loss*: \begin{align*}
\phi_{\tau}^{*} \in \arg\!\min_{\phi_{\tau}} \; & 
Y_t - g_{\phi_{m}^{*}}\left( GPT^{\text{path}}(X_{<t}) \right) \\
& - \left( W_t - g_{\phi_{e}^{*}}\left( GPT^{\text{path}}(X_{<t}) \right) \right)
\cdot g_{\phi_{\tau}}\left( GPT^{\text{path}}(X_{<t}) \right)
\end{align*}
:::


## Benchmarking {.unnumbered}

::: {.incremental}
- **How to compare embedding models ? What is a good embedding ?**
  1. Death prediction
  2. R-loss in a causal inference context (@abecassis:hal-04774700, @wagerCausalInferenceStatistical)

- **Competitors:**
  - SVD-PPMI (static embeddings)
  - BERT (pure embeddings, no trajectories)
    - MLM pre-training task (@life2vec)
    - **Temporal window masking task**
  - GPT with next-token + time-to-event task (@Shmatko2025)
:::

## Improvement of the pre-training task {.unnumbered}

- Going generative
- Count number of 

## Scaling {.unnumbered}

# References {.unnumbered}

## {.unnumbered}

::: {#refs}
:::